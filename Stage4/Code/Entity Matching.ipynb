{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "sys.path.append('/u/p/m/pmartinkus/Documents/CS_838/Stage 4')\n",
    "\n",
    "import Code as hw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import py_entitymatching as em\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking Step\n",
    "If we examine the length of the cartesian product of these two tables, we will see that there are too many pairs to check and too many of the pairs will not actually be matches. We can use a blocking step to remove obvious non-matches. This helps us reduce the total number of potential matches to check and also results in our data having a better ratio of matches to non-matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples in A: 3034\n",
      "Number of tuples in B: 3102\n",
      "Number of tuples in A X B (i.e the cartesian product): 9411468\n"
     ]
    }
   ],
   "source": [
    "print('Number of tuples in A: ' + str(len(A)))\n",
    "print('Number of tuples in B: ' + str(len(B)))\n",
    "print('Number of tuples in A X B (i.e the cartesian product): ' + str(len(A)*len(B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we will check that the two laptops have the same brand. Two laptops cannot be a match if they are not even made by the same company and the brand attribute is relatively clean in both tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644624"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create attribute equivalence blocker\n",
    "ab = em.AttrEquivalenceBlocker()\n",
    "\n",
    "# Block tables comparing the brand\n",
    "C1 = ab.block_tables(A, B, 'Brand', 'Brand',\n",
    "                   l_output_attrs=['Name', 'Price', 'Brand', 'Screen Size', 'RAM', 'Hard Drive Capacity', 'Processor Type', 'Processor Speed', 'Operating System', 'Clean Name'],\n",
    "                   r_output_attrs=['Name', 'Price', 'Brand', 'Screen Size', 'RAM', 'Hard Drive Capacity', 'Processor Type', 'Processor Speed', 'Operating System', 'Clean Name'])\n",
    "\n",
    "# Lets see how much we've reduced the size of the cadidate set\n",
    "len(C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every tuple pair in our candidate set C1 shares the same brand. Unfortunatly, there are still over a million tuples in this set so we need to continue blocking to reduce the size. Next, we will apply a rule based blocker. This blocker will check to see how similar the Clean Name columns of the tuple pair are using a jaccard score with 3-grams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column Battery Life does not seem to qualify as any atomic type. It may contain all NaNs. Please update the values of column Battery Life\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features for rule based blocking\n",
    "block_f = em.get_features_for_blocking(A, B, validate_inferred_attr_types=False)\n",
    "\n",
    "# Create the rule based blocker and add rule for jaccard score on Clean Name column\n",
    "rb = em.RuleBasedBlocker()\n",
    "rb.add_rule(['Clean_Name_Clean_Name_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.2'], block_f)\n",
    "\n",
    "# Block the candset\n",
    "C2 = rb.block_candset(C1)\n",
    "len(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have significantly reduced the size of the candidate set to around 65 thousand, but still only a small portion of the candidates can be actual matches. Since matching laptops should have the same size screen, RAM, and hard drive capacity, we will use a black box blocker to check if the numbers in the screen size field are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19052"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another black box blocker\n",
    "bb_screen = em.BlackBoxBlocker()\n",
    "# Set the black box function\n",
    "bb_screen.set_black_box_function((hw.screen_ram_hd_equal))\n",
    "# Apply blocker \n",
    "C = bb_screen.block_candset(C2)\n",
    "\n",
    "# Let's check the length of this candadate set\n",
    "len(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sufficently reduced the size of the candidate set, let's debug the blocking scheme to see if we left out any potential matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg = em.debug_blocker(C, A, B)\n",
    "dbg.to_csv(path+'debug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the candidate set to a csv file\n",
    "C.to_csv(path+'Candidate_Set.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Labeling\n",
    "\n",
    "Before we can start choosing a model, we need to label a set of data. First, we will randomly sample 300 candidate pairs of tuples and then we will manually label them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample candidate set\n",
    "S = em.sample_table(C, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Label S and specify the attribute name for the label column\n",
    "#L = em.label_table(S, 'gold')\n",
    "\n",
    "# Save Labeled data to csv file\n",
    "#L.to_csv(path+'Labeled_Data.csv', index=False)\n",
    "\n",
    "L = em.read_csv_metadata(path+'Labeled_Data.csv', \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_ID', fk_rtable='rtable_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "Now that we have a set of labeled data, we will create feature vectors for matching. We will use the features automatically generated by py_entitymatching. However, we don't need any features relating to brand since we already assured that the brands would match in the blocking stage. Additionally, many of the tuples are missing vlaues for battery life so we will not include any features based on that attribute either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column Battery Life does not seem to qualify as any atomic type. It may contain all NaNs. Please update the values of column Battery Life\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4        Name_Name_jac_qgm_3_qgm_3\n",
       "5    Name_Name_cos_dlm_dc0_dlm_dc0\n",
       "6                  Price_Price_exm\n",
       "7                  Price_Price_anm\n",
       "8             Price_Price_lev_dist\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)\n",
    "\n",
    "# We don't need any features relating to brand\n",
    "feature_subset = feature_table.iloc[np.r_[4:10, 40:len(feature_table)], :]\n",
    "\n",
    "# List the names of the features generated\n",
    "feature_subset['feature_name'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into a training set and a test set. The training set will be used for selecting our model, debugging the models, and training the final model. The test set is only used later on for evaluating the final model we settle on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labeled data into development and evaluation set\n",
    "development_evaluation = em.split_train_test(L, train_proportion=0.7)\n",
    "development =  development_evaluation['train']\n",
    "evaluation = development_evaluation['test']\n",
    "\n",
    "# Save sets I and J to csv files\n",
    "development.to_csv(path+'Development.csv', index=False)\n",
    "evaluation.to_csv(path+'Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>Name_Name_jac_qgm_3_qgm_3</th>\n",
       "      <th>Name_Name_cos_dlm_dc0_dlm_dc0</th>\n",
       "      <th>Price_Price_exm</th>\n",
       "      <th>Price_Price_anm</th>\n",
       "      <th>Price_Price_lev_dist</th>\n",
       "      <th>Price_Price_lev_sim</th>\n",
       "      <th>Processor_Speed_Processor_Speed_jac_qgm_3_qgm_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating_System_Operating_System_lev_dist</th>\n",
       "      <th>Operating_System_Operating_System_lev_sim</th>\n",
       "      <th>Operating_System_Operating_System_nmw</th>\n",
       "      <th>Operating_System_Operating_System_sw</th>\n",
       "      <th>Clean_Name_Clean_Name_jac_qgm_3_qgm_3</th>\n",
       "      <th>Clean_Name_Clean_Name_cos_dlm_dc0_dlm_dc0</th>\n",
       "      <th>Clean_Name_Clean_Name_mel</th>\n",
       "      <th>Clean_Name_Clean_Name_lev_dist</th>\n",
       "      <th>Clean_Name_Clean_Name_lev_sim</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>283662</td>\n",
       "      <td>167</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.189055</td>\n",
       "      <td>0.359092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.784166</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>478739</td>\n",
       "      <td>282</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.406114</td>\n",
       "      <td>0.464642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925033</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.693290</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11792</td>\n",
       "      <td>6</td>\n",
       "      <td>3004</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.382692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977098</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>0.666835</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id  ltable_ID  rtable_ID  Name_Name_jac_qgm_3_qgm_3  \\\n",
       "130  283662        167       2011                   0.189055   \n",
       "171  478739        282       2925                   0.406114   \n",
       "23    11792          6       3004                   0.345361   \n",
       "\n",
       "     Name_Name_cos_dlm_dc0_dlm_dc0  Price_Price_exm  Price_Price_anm  \\\n",
       "130                       0.359092              0.0         0.926780   \n",
       "171                       0.464642              0.0         0.925033   \n",
       "23                        0.382692              0.0         0.977098   \n",
       "\n",
       "     Price_Price_lev_dist  Price_Price_lev_sim  \\\n",
       "130                   5.0             0.166667   \n",
       "171                   3.0             0.500000   \n",
       "23                    4.0             0.333333   \n",
       "\n",
       "     Processor_Speed_Processor_Speed_jac_qgm_3_qgm_3  ...   \\\n",
       "130                                              NaN  ...    \n",
       "171                                              NaN  ...    \n",
       "23                                          0.285714  ...    \n",
       "\n",
       "     Operating_System_Operating_System_lev_dist  \\\n",
       "130                                         0.0   \n",
       "171                                         0.0   \n",
       "23                                          0.0   \n",
       "\n",
       "     Operating_System_Operating_System_lev_sim  \\\n",
       "130                                        1.0   \n",
       "171                                        1.0   \n",
       "23                                         1.0   \n",
       "\n",
       "     Operating_System_Operating_System_nmw  \\\n",
       "130                                   10.0   \n",
       "171                                   10.0   \n",
       "23                                    10.0   \n",
       "\n",
       "     Operating_System_Operating_System_sw  \\\n",
       "130                                  10.0   \n",
       "171                                  10.0   \n",
       "23                                   10.0   \n",
       "\n",
       "     Clean_Name_Clean_Name_jac_qgm_3_qgm_3  \\\n",
       "130                               0.211268   \n",
       "171                               0.457143   \n",
       "23                                0.324675   \n",
       "\n",
       "     Clean_Name_Clean_Name_cos_dlm_dc0_dlm_dc0  Clean_Name_Clean_Name_mel  \\\n",
       "130                                   0.353553                   0.784166   \n",
       "171                                   0.577350                   0.693290   \n",
       "23                                    0.503953                   0.666835   \n",
       "\n",
       "     Clean_Name_Clean_Name_lev_dist  Clean_Name_Clean_Name_lev_sim  gold  \n",
       "130                            37.0                       0.339286     0  \n",
       "171                            27.0                       0.571429     1  \n",
       "23                             35.0                       0.363636     1  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature vectors\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, \n",
    "                            feature_table=feature_subset, \n",
    "                            attrs_after='gold')\n",
    "# Display first few rows\n",
    "feature_vectors_dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "any(pd.isnull(feature_vectors_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Matcher\n",
    "\n",
    "Using the feature vectors we created, we can create some ML models and select the one that performs best. We will be selecting between the following methods: Decision Tree, SVM, Random Forest, Naive Bayes, Logistic Regression, and Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree')\n",
    "svm = em.SVMMatcher(name='SVM')\n",
    "rf = em.RFMatcher(name='RF')\n",
    "nb = em.NBMatcher(name='NB')\n",
    "lg = em.LogRegMatcher(name='LogReg')\n",
    "ln = em.LinRegMatcher(name='LinReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best ML matcher using Cross Validation\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', \n",
    "        metric_to_select_matcher='f1',\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.910598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.882937</td>\n",
       "      <td>0.910717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.757738</td>\n",
       "      <td>0.671825</td>\n",
       "      <td>0.693077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.576190</td>\n",
       "      <td>0.544761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.529365</td>\n",
       "      <td>0.569893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.711829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.917500        0.919048    0.910598\n",
       "1            RF           0.940714        0.882937    0.910717\n",
       "2           SVM           0.757738        0.671825    0.693077\n",
       "3            NB           0.570000        0.576190    0.544761\n",
       "4        LogReg           0.670000        0.529365    0.569893\n",
       "5        LinReg           0.842381        0.630556    0.711829"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take a look at the average results for cross validation for each matcher\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging a Matcher\n",
    "\n",
    "The next step is to debug the matcher we have chosen. We will examine the false positives and false negative to try and look for some common patterns to our errors. This way, we can make changes to address these common problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split feature vectors into train and test\n",
    "train_test = em.split_train_test(feature_vectors_dev, train_proportion=0.5)\n",
    "train = train_test['train']\n",
    "test = train_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug decision tree using GUI\n",
    "em.vis_debug_rf(rf, train, test, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "        target_attr='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a look at the false positives and negatives using the debugger, we discovered that the random forest model has trouble differentiated referbished laptops from new laptops. We can add a new feature that checks if the two laptops are refurbished to help with this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new feature to check if laptops are refurbished or not\n",
    "em.add_blackbox_feature(feature_subset, 'refurbished', hw.refurbished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can select a model again to see how our new refurbish feature affected performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Extract feature vectors\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, \n",
    "                            feature_table=feature_subset, \n",
    "                            attrs_after='gold')\n",
    "\n",
    "# Impute feature vectors with the mean of the column values.\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "                strategy='mean')\n",
    "\n",
    "# Select the best ML matcher using Cross Validation\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', \n",
    "        metric_to_select_matcher='f1',\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.913929</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.910598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.938492</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.927661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.784545</td>\n",
       "      <td>0.671825</td>\n",
       "      <td>0.706125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.714405</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.682251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.728095</td>\n",
       "      <td>0.558532</td>\n",
       "      <td>0.616865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.812381</td>\n",
       "      <td>0.655952</td>\n",
       "      <td>0.721434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.913929        0.919048    0.910598\n",
       "1            RF           0.938492        0.927778    0.927661\n",
       "2           SVM           0.784545        0.671825    0.706125\n",
       "3            NB           0.714405        0.688889    0.682251\n",
       "4        LogReg           0.728095        0.558532    0.616865\n",
       "5        LinReg           0.812381        0.655952    0.721434"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the Random Forest model has improved due to the debugging and is now the best performing matcher on our development set. We can move forward and test it out on the evaluation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Matchers\n",
    "\n",
    "Next, we will evaluate the matchers on the test dataset that we set aside earlier. Up until this point we have not looked at the evaluation set at all. The hope is that the evaluation set is representative of the complete data set (after blocking) and we have not overfit it since we have not looked at it.\n",
    "\n",
    "First, we need to create feature vectors from the evaluation set. These features will be the same as before and will include our refurbished feature we developed after debuggin the matchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get new set of features\n",
    "feature_vectors_eval = em.extract_feature_vecs(evaluation, \n",
    "                                               feature_table=feature_subset, \n",
    "                                               attrs_after='gold')\n",
    "\n",
    "# Impute feature vectors\n",
    "feature_vectors_eval = em.impute_table(feature_vectors_eval, \n",
    "                exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fit the models on the entire development set. This will give us a model that can be used to predict matches in the evaluation set. Then, using the trained model, we will generate predictions for the entire evaluation set and report the accuracies for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using feature vectors from the development set\n",
    "matchers = [dt, rf, svm, nb, lg, ln]\n",
    "for matcher in matchers:\n",
    "    matcher.fit(table=feature_vectors_dev, \n",
    "           exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'], \n",
    "           target_attr='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict M for each matcher\n",
    "predictions = []\n",
    "for matcher in matchers:\n",
    "    predictions.append(matcher.predict(table=feature_vectors_eval, \n",
    "                             exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'gold'], \n",
    "                             append=True, \n",
    "                             target_attr='predicted', \n",
    "                             inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: \n",
      "Precision : 92.86% (26/28)\n",
      "Recall : 96.3% (26/27)\n",
      "F1 : 94.55%\n",
      "False positives : 2 (out of 28 positive predictions)\n",
      "False negatives : 1 (out of 62 negative predictions)\n",
      "\n",
      "RF: \n",
      "Precision : 100.0% (24/24)\n",
      "Recall : 88.89% (24/27)\n",
      "F1 : 94.12%\n",
      "False positives : 0 (out of 24 positive predictions)\n",
      "False negatives : 3 (out of 66 negative predictions)\n",
      "\n",
      "SVM: \n",
      "Precision : 66.67% (16/24)\n",
      "Recall : 59.26% (16/27)\n",
      "F1 : 62.75%\n",
      "False positives : 8 (out of 24 positive predictions)\n",
      "False negatives : 11 (out of 66 negative predictions)\n",
      "\n",
      "NB: \n",
      "Precision : 56.67% (17/30)\n",
      "Recall : 62.96% (17/27)\n",
      "F1 : 59.65%\n",
      "False positives : 13 (out of 30 positive predictions)\n",
      "False negatives : 10 (out of 60 negative predictions)\n",
      "\n",
      "LogReg: \n",
      "Precision : 69.23% (9/13)\n",
      "Recall : 33.33% (9/27)\n",
      "F1 : 45.0%\n",
      "False positives : 4 (out of 13 positive predictions)\n",
      "False negatives : 18 (out of 77 negative predictions)\n",
      "\n",
      "LinReg: \n",
      "Precision : 89.47% (17/19)\n",
      "Recall : 62.96% (17/27)\n",
      "F1 : 73.91%\n",
      "False positives : 2 (out of 19 positive predictions)\n",
      "False negatives : 10 (out of 71 negative predictions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the result\n",
    "for i, matcher in enumerate(matchers):\n",
    "    print(matcher.name + ': ')\n",
    "    eval_result = em.eval_matches(predictions[i], 'gold', 'predicted')\n",
    "    em.print_eval_summary(eval_result)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the Random Forest model has performed well on the test set nearly reaching a 95% F1 score. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
